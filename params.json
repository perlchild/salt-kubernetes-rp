{
  "name": "Salt-kubernetes-rp",
  "tagline": "Gathering the code I gathered/modified for hackathon",
  "body": "#Hackathon XI at Radialpoint, I'm going through this walkthrough and code, and integrating others, to enable a proof of concept for:\r\n\r\n- Kubernetes use at rp, including resource clusters\r\n- Salt support of autoscaling@aws\r\n- kubernetes-supported docker images\r\n\r\n![Kubernetes logo, I don't own this.](http://perlchild.github.io/salt-kubernetes-rp/kuber.png)\r\n\r\n***\r\n    export INSTANCE_PREFIX=k8s\r\n    export AWS_S3_BUCKET=radialpoint-k8s-artifacts\r\n    export AWS_S3_REGION=us-east-1\r\n    export KUBE_AWS_ZONE=us-east-1c\r\n    export AWS_SSH_KEY=/home/ericr/.ssh/rsa\r\n    export KUBE_AWS_ZONE=us-east-1e\r\n    export MASTER_SIZE=t2.large\r\n    export NODE_SIZE=t2.large\r\n    # export KUBERNETES_PROVIDER=aws; curl -sS https://get.k8s.io | bash #Only the first time\r\n    bash ./kube-up.sh \r\n    kubectl cluster-info\r\n\r\n***\r\n\r\nThis returns\r\n\r\n    Kubernetes master is running at https://52.0.84.8\r\n    Elasticsearch is running at https://52.0.84.8/api/v1/proxy/namespaces/kube-system/services/elasticsearch-logging\r\n    Heapster is running at https://52.0.84.8/api/v1/proxy/namespaces/kube-system/services/heapster\r\n    Kibana is running at https://52.0.84.8/api/v1/proxy/namespaces/kube-system/services/kibana-logging\r\n    KubeDNS is running at https://52.0.84.8/api/v1/proxy/namespaces/kube-system/services/kube-dns\r\n    kubernetes-dashboard is running at https://52.0.84.8/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard\r\n    Grafana is running at https://52.0.84.8/api/v1/proxy/namespaces/kube-system/services/monitoring-grafana\r\n    InfluxDB is running at https://52.0.84.8/api/v1/proxy/namespaces/kube-system/services/monitoring-influxdb\r\n\r\n***\r\n\r\n    cd ~/kubernetes/examples/javaee\r\n    kubectl create -f .\r\n    pod \"mysql-pod\" created\r\n    service \"mysql-service\" created\r\n    replicationcontroller \"wildfly-rc\" created\r\n\r\n    cd ~/kubernetes/examples/mysql-galera\r\n    kubectl create -f .\r\n    service \"pxc-cluster\" created\r\n    service \"pxc-node1\" created\r\n    replicationcontroller \"pxc-node1\" created\r\n    service \"pxc-node2\" created\r\n    replicationcontroller \"pxc-node2\" created\r\n    service \"pxc-node3\" created\r\n    replicationcontroller \"pxc-node3\" created\r\n  \r\nSo, in short order, I've created two mysql databases, one replicating, and one java application.\r\n\r\nI also get support services, like kibana and grafana\r\n![kibana view ](http://perlchild.github.io/salt-kubernetes-rp/kibana1.png)\r\n\r\n![dashboard view ](http://perlchild.github.io/salt-kubernetes-rp/dashboard.png)\r\n\r\n![Autoscaling group ](http://perlchild.github.io/salt-kubernetes-rp/kubernetes_asg.png)\r\n\r\n![Top container usage by pod](http://perlchild.github.io/salt-kubernetes-rp/topkibana.png)\r\n***\r\nI've also tested an autoscaling policy\r\n\r\n`    {\r\n        \"ScalingPolicies\": [\r\n            {\r\n                \"PolicyName\": \"WayTooSpend\", \r\n                \"MetricAggregationType\": \"Maximum\", \r\n                \"AutoScalingGroupName\": \"kubernetes-minion-group-us-east-1e\", \r\n                \"PolicyARN\": \"arn:aws:autoscaling:us-east-1:151354380905:scalingPolicy:6f88279a-e96c-464b-a903-d1809a054c94:autoScalingGroupName/kubernetes-minion-group-us-east-1e:policyName/WayTooSpend\", \r\n                \"PolicyType\": \"StepScaling\", \r\n                \"StepAdjustments\": [\r\n                    {\r\n                        \"ScalingAdjustment\": -1, \r\n                        \"MetricIntervalLowerBound\": 0.0\r\n                    }\r\n                ], \r\n                \"AdjustmentType\": \"ChangeInCapacity\", \r\n                \"Alarms\": [\r\n                    {\r\n                        \"AlarmName\": \"BillingAlarm\", \r\n                        \"AlarmARN\": \"arn:aws:cloudwatch:us-east-1:151354380905:alarm:BillingAlarm\"\r\n                    }\r\n                ]\r\n            }, \r\n            {\r\n                \"PolicyName\": \"cpuutil\", \r\n                \"EstimatedInstanceWarmup\": 300, \r\n                \"MetricAggregationType\": \"Average\", \r\n                \"AutoScalingGroupName\": \"kubernetes-minion-group-us-east-1e\", \r\n                \"PolicyARN\": \"arn:aws:autoscaling:us-east-1:151354380905:scalingPolicy:f15f4a84-e4f2-4f86-b109-2c73780eefe0:autoScalingGroupName/kubernetes-minion-group-us-east-1e:policyName/cpuutil\", \r\n                \"PolicyType\": \"StepScaling\", \r\n                \"StepAdjustments\": [\r\n                    {\r\n                        \"ScalingAdjustment\": 1, \r\n                        \"MetricIntervalLowerBound\": 0.0\r\n                    }\r\n                ], \r\n                \"AdjustmentType\": \"ChangeInCapacity\", \r\n                \"Alarms\": [\r\n                    {\r\n                        \"AlarmName\": \"awsec2-kubernetes-minion-group-us-east-1e-CPU-Utilization\", \r\n                        \"AlarmARN\": \"arn:aws:cloudwatch:us-east-1:151354380905:alarm:awsec2-kubernetes-minion-group-us-east-1e-CPU-Utilization\"\r\n                    }\r\n                ]\r\n            }\r\n        ]\r\n    }`",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}